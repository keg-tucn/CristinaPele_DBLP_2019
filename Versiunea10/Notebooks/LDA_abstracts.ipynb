{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesare abstracte\n",
    "Tutorial: https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_abs(path_to_file, all_abstr):\n",
    "    r = open(path_to_file, 'r', encoding='utf-8')\n",
    "    \n",
    "    for paper in r:\n",
    "        crt_paper = json.loads(paper)\n",
    "        crt_indexed_abstr = crt_paper['indexed_abstract']\n",
    "        crt_abstr = []\n",
    "        for word in crt_indexed_abstr:\n",
    "            for i in range(0,crt_indexed_abstr[word]):\n",
    "                crt_abstr.append(word)\n",
    "        \n",
    "        all_abstr.append(crt_abstr)\n",
    "        \n",
    "    r.close()\n",
    "    return all_abstr\n",
    "\n",
    "all_abstr = []\n",
    "for i in range(0,33):\n",
    "    path_to_abstr = 'dblp_data/preprocessedIA/file' + str(i) + '.txt'\n",
    "    all_abstr = create_abs(path_to_abstr,all_abstr)\n",
    "#path_to_abstr = '../../dblp_data/preprocessedIA/file1.txt'\n",
    "#all_abstr = create_abs(path_to_abstr,all_abstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter out tokens that appear in\n",
    "\n",
    "- less than 15 documents (absolute number) or\n",
    "- more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "- after the above two steps, keep only the first 100000 most frequent tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cloud', 'access', 'access', 'arise', 'require', 'enforce', 'enforce', 'enable', 'provide', 'accord', 'propose', 'propose', 'allow', 'abide', 'assure', 'exploit', 'trust', 'attest', 'suggest'], ['present', 'close', 'exceed']]\n"
     ]
    }
   ],
   "source": [
    "print(all_abstr[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(all_abstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.35, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4260\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in all_abstr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=56, id2word=dictionary, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.184*\"check\" + 0.157*\"trace\" + 0.053*\"signal\" + 0.039*\"blur\" + 0.038*\"query\" + 0.036*\"fuel\" + 0.032*\"jump\" + 0.026*\"sign\" + 0.024*\"power\" + 0.020*\"function\"\n",
      "Topic: 1 \n",
      "Words: 0.094*\"schedule\" + 0.092*\"minimize\" + 0.084*\"total\" + 0.056*\"maximize\" + 0.040*\"optimize\" + 0.037*\"consider\" + 0.036*\"manufacture\" + 0.022*\"cut\" + 0.018*\"base\" + 0.018*\"achieve\"\n",
      "Topic: 2 \n",
      "Words: 0.372*\"know\" + 0.105*\"discover\" + 0.038*\"localize\" + 0.026*\"score\" + 0.025*\"screen\" + 0.016*\"base\" + 0.016*\"jam\" + 0.015*\"present\" + 0.014*\"identify\" + 0.013*\"work\"\n",
      "Topic: 3 \n",
      "Words: 0.234*\"share\" + 0.174*\"sense\" + 0.130*\"cover\" + 0.045*\"frequent\" + 0.030*\"alternate\" + 0.029*\"drop\" + 0.018*\"push\" + 0.016*\"term\" + 0.014*\"condition\" + 0.014*\"iterate\"\n",
      "Topic: 4 \n",
      "Words: 0.371*\"cluster\" + 0.186*\"tree\" + 0.040*\"base\" + 0.025*\"parse\" + 0.020*\"span\" + 0.016*\"compare\" + 0.015*\"present\" + 0.013*\"improve\" + 0.012*\"apply\" + 0.011*\"perform\"\n",
      "Topic: 5 \n",
      "Words: 0.147*\"perceive\" + 0.138*\"die\" + 0.129*\"analyse\" + 0.120*\"argue\" + 0.075*\"rise\" + 0.064*\"fall\" + 0.037*\"regulate\" + 0.026*\"cascade\" + 0.024*\"talk\" + 0.019*\"impact\"\n",
      "Topic: 6 \n",
      "Words: 0.617*\"process\" + 0.023*\"present\" + 0.020*\"base\" + 0.012*\"develop\" + 0.012*\"apply\" + 0.011*\"involve\" + 0.011*\"require\" + 0.010*\"make\" + 0.010*\"describe\" + 0.010*\"provide\"\n",
      "Topic: 7 \n",
      "Words: 0.133*\"derive\" + 0.065*\"pair\" + 0.053*\"approximate\" + 0.037*\"fit\" + 0.035*\"base\" + 0.031*\"miss\" + 0.030*\"angle\" + 0.028*\"present\" + 0.027*\"compute\" + 0.025*\"obtain\"\n",
      "Topic: 8 \n",
      "Words: 0.492*\"set\" + 0.106*\"define\" + 0.019*\"introduce\" + 0.019*\"present\" + 0.017*\"base\" + 0.017*\"consider\" + 0.014*\"generate\" + 0.012*\"call\" + 0.011*\"obtain\" + 0.011*\"provide\"\n",
      "Topic: 9 \n",
      "Words: 0.298*\"verify\" + 0.121*\"hold\" + 0.077*\"merge\" + 0.051*\"age\" + 0.036*\"trust\" + 0.035*\"split\" + 0.024*\"authenticate\" + 0.022*\"react\" + 0.021*\"nurse\" + 0.017*\"log\"\n",
      "Topic: 10 \n",
      "Words: 0.235*\"run\" + 0.118*\"file\" + 0.094*\"bound\" + 0.079*\"store\" + 0.043*\"cache\" + 0.035*\"isolate\" + 0.035*\"access\" + 0.030*\"relax\" + 0.027*\"download\" + 0.017*\"listen\"\n",
      "Topic: 11 \n",
      "Words: 0.174*\"train\" + 0.095*\"select\" + 0.058*\"base\" + 0.045*\"classify\" + 0.028*\"improve\" + 0.025*\"achieve\" + 0.025*\"compare\" + 0.024*\"label\" + 0.022*\"perform\" + 0.021*\"outperform\"\n",
      "Topic: 12 \n",
      "Words: 0.126*\"detect\" + 0.065*\"base\" + 0.042*\"evaluate\" + 0.033*\"balance\" + 0.033*\"divide\" + 0.024*\"present\" + 0.024*\"compare\" + 0.022*\"identify\" + 0.019*\"range\" + 0.018*\"improve\"\n",
      "Topic: 13 \n",
      "Words: 0.234*\"give\" + 0.050*\"satisfy\" + 0.043*\"consider\" + 0.029*\"present\" + 0.025*\"fix\" + 0.024*\"obtain\" + 0.022*\"desire\" + 0.021*\"assume\" + 0.017*\"show\" + 0.017*\"guarantee\"\n",
      "Topic: 14 \n",
      "Words: 0.371*\"plan\" + 0.096*\"plant\" + 0.072*\"firm\" + 0.028*\"unman\" + 0.020*\"interleave\" + 0.019*\"develop\" + 0.017*\"generate\" + 0.014*\"invest\" + 0.012*\"fracture\" + 0.012*\"present\"\n",
      "Topic: 15 \n",
      "Words: 0.168*\"rat\" + 0.059*\"reconstruct\" + 0.048*\"fade\" + 0.034*\"tweet\" + 0.033*\"decentralize\" + 0.027*\"consider\" + 0.026*\"tailor\" + 0.023*\"achieve\" + 0.023*\"port\" + 0.022*\"neighbor\"\n",
      "Topic: 16 \n",
      "Words: 0.205*\"model\" + 0.111*\"predict\" + 0.062*\"open\" + 0.053*\"pose\" + 0.045*\"capture\" + 0.041*\"base\" + 0.030*\"present\" + 0.027*\"walk\" + 0.021*\"develop\" + 0.016*\"provide\"\n",
      "Topic: 17 \n",
      "Words: 0.348*\"construct\" + 0.160*\"yield\" + 0.084*\"correlate\" + 0.045*\"boost\" + 0.021*\"undergo\" + 0.018*\"pool\" + 0.018*\"base\" + 0.015*\"sell\" + 0.013*\"hypothesize\" + 0.013*\"buy\"\n",
      "Topic: 18 \n",
      "Words: 0.101*\"measure\" + 0.084*\"automate\" + 0.057*\"rank\" + 0.034*\"return\" + 0.032*\"assess\" + 0.026*\"evaluate\" + 0.025*\"base\" + 0.025*\"quantify\" + 0.025*\"scatter\" + 0.024*\"recall\"\n",
      "Topic: 19 \n",
      "Words: 0.263*\"cod\" + 0.160*\"transform\" + 0.049*\"encode\" + 0.034*\"base\" + 0.031*\"pass\" + 0.024*\"achieve\" + 0.021*\"present\" + 0.017*\"alter\" + 0.017*\"compare\" + 0.015*\"apply\"\n",
      "Topic: 20 \n",
      "Words: 0.147*\"experience\" + 0.141*\"create\" + 0.056*\"recognize\" + 0.030*\"present\" + 0.028*\"annotate\" + 0.020*\"view\" + 0.018*\"provide\" + 0.016*\"play\" + 0.016*\"interact\" + 0.015*\"develop\"\n",
      "Topic: 21 \n",
      "Words: 0.176*\"simulate\" + 0.100*\"hide\" + 0.092*\"switch\" + 0.046*\"compress\" + 0.041*\"degrade\" + 0.036*\"break\" + 0.030*\"price\" + 0.023*\"base\" + 0.021*\"govern\" + 0.019*\"overload\"\n",
      "Topic: 22 \n",
      "Words: 0.150*\"weight\" + 0.085*\"scale\" + 0.051*\"register\" + 0.046*\"normalize\" + 0.039*\"base\" + 0.035*\"smooth\" + 0.029*\"average\" + 0.023*\"narrow\" + 0.023*\"mean\" + 0.023*\"compare\"\n",
      "Topic: 23 \n",
      "Words: 0.232*\"filter\" + 0.108*\"drive\" + 0.047*\"time\" + 0.041*\"render\" + 0.037*\"base\" + 0.034*\"position\" + 0.030*\"present\" + 0.016*\"compensate\" + 0.015*\"clean\" + 0.014*\"improve\"\n",
      "Topic: 24 \n",
      "Words: 0.161*\"reduce\" + 0.069*\"improve\" + 0.052*\"gain\" + 0.041*\"transfer\" + 0.040*\"achieve\" + 0.036*\"compare\" + 0.034*\"base\" + 0.022*\"present\" + 0.018*\"require\" + 0.017*\"show\"\n",
      "Topic: 25 \n",
      "Words: 0.120*\"produce\" + 0.100*\"mean\" + 0.062*\"observe\" + 0.038*\"shift\" + 0.026*\"generate\" + 0.026*\"show\" + 0.023*\"interpret\" + 0.021*\"form\" + 0.017*\"prefer\" + 0.016*\"investigate\"\n",
      "Topic: 26 \n",
      "Words: 0.511*\"test\" + 0.041*\"forecast\" + 0.028*\"base\" + 0.027*\"generate\" + 0.024*\"present\" + 0.020*\"compare\" + 0.018*\"perform\" + 0.017*\"develop\" + 0.016*\"seed\" + 0.015*\"weather\"\n",
      "Topic: 27 \n",
      "Words: 0.193*\"update\" + 0.097*\"list\" + 0.063*\"compact\" + 0.059*\"post\" + 0.043*\"slow\" + 0.039*\"compete\" + 0.035*\"harvest\" + 0.030*\"drift\" + 0.029*\"decouple\" + 0.027*\"allocate\"\n",
      "Topic: 28 \n",
      "Words: 0.154*\"request\" + 0.120*\"leave\" + 0.102*\"retrieve\" + 0.092*\"search\" + 0.056*\"join\" + 0.033*\"overlay\" + 0.033*\"enter\" + 0.021*\"duplicate\" + 0.018*\"group\" + 0.016*\"be\"\n",
      "Topic: 29 \n",
      "Words: 0.200*\"cloud\" + 0.152*\"offer\" + 0.047*\"deliver\" + 0.038*\"deploy\" + 0.036*\"charge\" + 0.033*\"provide\" + 0.023*\"surround\" + 0.016*\"enforce\" + 0.016*\"market\" + 0.014*\"outsource\"\n",
      "Topic: 30 \n",
      "Words: 0.116*\"change\" + 0.113*\"adapt\" + 0.111*\"serve\" + 0.102*\"evolve\" + 0.041*\"overlap\" + 0.036*\"respond\" + 0.017*\"roll\" + 0.014*\"premise\" + 0.013*\"cool\" + 0.013*\"crash\"\n",
      "Topic: 31 \n",
      "Words: 0.164*\"represent\" + 0.050*\"express\" + 0.049*\"reason\" + 0.046*\"specify\" + 0.039*\"publish\" + 0.033*\"infer\" + 0.030*\"present\" + 0.028*\"base\" + 0.024*\"provide\" + 0.021*\"drug\"\n",
      "Topic: 32 \n",
      "Words: 0.121*\"implement\" + 0.103*\"allow\" + 0.062*\"present\" + 0.053*\"monitor\" + 0.040*\"base\" + 0.038*\"provide\" + 0.029*\"operate\" + 0.025*\"work\" + 0.023*\"develop\" + 0.022*\"require\"\n",
      "Topic: 33 \n",
      "Words: 0.263*\"map\" + 0.169*\"match\" + 0.060*\"name\" + 0.053*\"coordinate\" + 0.031*\"base\" + 0.029*\"format\" + 0.022*\"present\" + 0.021*\"align\" + 0.020*\"generate\" + 0.012*\"demonstrate\"\n",
      "Topic: 34 \n",
      "Words: 0.522*\"learn\" + 0.019*\"base\" + 0.018*\"personalize\" + 0.016*\"improve\" + 0.015*\"demonstrate\" + 0.015*\"work\" + 0.012*\"present\" + 0.012*\"provide\" + 0.011*\"apply\" + 0.010*\"supervise\"\n",
      "Topic: 35 \n",
      "Words: 0.115*\"receive\" + 0.095*\"transmit\" + 0.072*\"record\" + 0.070*\"save\" + 0.057*\"locate\" + 0.036*\"synthesize\" + 0.023*\"finger\" + 0.023*\"adjust\" + 0.023*\"achieve\" + 0.022*\"visit\"\n",
      "Topic: 36 \n",
      "Words: 0.421*\"graph\" + 0.117*\"direct\" + 0.071*\"mix\" + 0.036*\"induce\" + 0.026*\"mask\" + 0.021*\"compound\" + 0.020*\"color\" + 0.013*\"contain\" + 0.012*\"connect\" + 0.011*\"call\"\n",
      "Topic: 37 \n",
      "Words: 0.411*\"abstract\" + 0.059*\"stream\" + 0.035*\"concrete\" + 0.025*\"predicate\" + 0.025*\"present\" + 0.025*\"customize\" + 0.021*\"stabilize\" + 0.021*\"rewrite\" + 0.019*\"ship\" + 0.016*\"pick\"\n",
      "Topic: 38 \n",
      "Words: 0.055*\"understand\" + 0.042*\"identify\" + 0.037*\"find\" + 0.037*\"suggest\" + 0.034*\"examine\" + 0.030*\"work\" + 0.022*\"provide\" + 0.022*\"relate\" + 0.021*\"investigate\" + 0.021*\"explore\"\n",
      "Topic: 39 \n",
      "Words: 0.264*\"message\" + 0.160*\"couple\" + 0.090*\"communicate\" + 0.080*\"send\" + 0.033*\"fabricate\" + 0.032*\"pack\" + 0.023*\"exchange\" + 0.019*\"pass\" + 0.015*\"shorten\" + 0.013*\"disseminate\"\n",
      "Topic: 40 \n",
      "Words: 0.358*\"build\" + 0.082*\"manage\" + 0.055*\"count\" + 0.035*\"interconnect\" + 0.022*\"provide\" + 0.021*\"offload\" + 0.020*\"work\" + 0.020*\"base\" + 0.017*\"present\" + 0.016*\"profile\"\n",
      "Topic: 41 \n",
      "Words: 0.247*\"embed\" + 0.231*\"block\" + 0.077*\"reuse\" + 0.068*\"broadcast\" + 0.034*\"touch\" + 0.023*\"mark\" + 0.014*\"achieve\" + 0.013*\"base\" + 0.012*\"tolerate\" + 0.012*\"present\"\n",
      "Topic: 42 \n",
      "Words: 0.075*\"ensure\" + 0.062*\"secure\" + 0.041*\"provide\" + 0.036*\"prevent\" + 0.031*\"protect\" + 0.026*\"base\" + 0.024*\"exist\" + 0.024*\"address\" + 0.019*\"compromise\" + 0.019*\"mitigate\"\n",
      "Topic: 43 \n",
      "Words: 0.206*\"prove\" + 0.107*\"complete\" + 0.089*\"label\" + 0.054*\"preserve\" + 0.051*\"free\" + 0.038*\"decide\" + 0.021*\"speak\" + 0.021*\"edit\" + 0.020*\"introduce\" + 0.019*\"exact\"\n",
      "Topic: 44 \n",
      "Words: 0.236*\"delay\" + 0.117*\"answer\" + 0.112*\"meet\" + 0.051*\"survey\" + 0.023*\"ask\" + 0.023*\"wait\" + 0.022*\"provide\" + 0.021*\"pitch\" + 0.019*\"waste\" + 0.018*\"convey\"\n",
      "Topic: 45 \n",
      "Words: 0.192*\"rout\" + 0.143*\"generalize\" + 0.051*\"travel\" + 0.048*\"converge\" + 0.043*\"route\" + 0.026*\"hop\" + 0.025*\"base\" + 0.020*\"consider\" + 0.019*\"sink\" + 0.016*\"fly\"\n",
      "Topic: 46 \n",
      "Words: 0.325*\"extract\" + 0.116*\"report\" + 0.057*\"gather\" + 0.047*\"let\" + 0.042*\"visualize\" + 0.040*\"crowd\" + 0.034*\"denote\" + 0.029*\"manipulate\" + 0.022*\"bear\" + 0.021*\"contain\"\n",
      "Topic: 47 \n",
      "Words: 0.257*\"solve\" + 0.058*\"supply\" + 0.056*\"formulate\" + 0.047*\"sit\" + 0.047*\"constrain\" + 0.031*\"base\" + 0.029*\"present\" + 0.023*\"consider\" + 0.020*\"index\" + 0.018*\"apply\"\n",
      "Topic: 48 \n",
      "Words: 0.136*\"integrate\" + 0.062*\"provide\" + 0.048*\"enable\" + 0.044*\"write\" + 0.035*\"network\" + 0.031*\"present\" + 0.030*\"develop\" + 0.029*\"assist\" + 0.022*\"exist\" + 0.018*\"emerge\"\n",
      "Topic: 49 \n",
      "Words: 0.197*\"connect\" + 0.109*\"compose\" + 0.107*\"scan\" + 0.095*\"augment\" + 0.034*\"sequence\" + 0.030*\"hash\" + 0.029*\"browse\" + 0.026*\"nest\" + 0.016*\"shallow\" + 0.016*\"spike\"\n",
      "Topic: 50 \n",
      "Words: 0.063*\"demand\" + 0.055*\"advance\" + 0.048*\"provide\" + 0.032*\"grow\" + 0.031*\"increase\" + 0.029*\"present\" + 0.026*\"facilitate\" + 0.026*\"structure\" + 0.025*\"develop\" + 0.024*\"support\"\n",
      "Topic: 51 \n",
      "Words: 0.083*\"estimate\" + 0.080*\"obtain\" + 0.070*\"calculate\" + 0.056*\"base\" + 0.035*\"grind\" + 0.032*\"compare\" + 0.029*\"present\" + 0.026*\"apply\" + 0.020*\"determine\" + 0.017*\"show\"\n",
      "Topic: 52 \n",
      "Words: 0.187*\"project\" + 0.059*\"read\" + 0.050*\"develop\" + 0.046*\"work\" + 0.028*\"describe\" + 0.026*\"orient\" + 0.025*\"present\" + 0.025*\"aim\" + 0.018*\"provide\" + 0.017*\"include\"\n",
      "Topic: 53 \n",
      "Words: 0.158*\"track\" + 0.083*\"move\" + 0.073*\"reach\" + 0.047*\"recover\" + 0.030*\"base\" + 0.029*\"present\" + 0.027*\"fuse\" + 0.025*\"contract\" + 0.020*\"demonstrate\" + 0.015*\"achieve\"\n",
      "Topic: 54 \n",
      "Words: 0.255*\"lower\" + 0.208*\"bind\" + 0.080*\"simplify\" + 0.033*\"randomize\" + 0.031*\"rest\" + 0.022*\"show\" + 0.020*\"debug\" + 0.020*\"obtain\" + 0.019*\"improve\" + 0.019*\"provide\"\n",
      "Topic: 55 \n",
      "Words: 0.379*\"distribute\" + 0.053*\"order\" + 0.047*\"cross\" + 0.040*\"centralize\" + 0.036*\"repeat\" + 0.026*\"accept\" + 0.021*\"trade\" + 0.017*\"cooperate\" + 0.012*\"require\" + 0.011*\"base\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
