{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library')\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(path, range_, camp, key, keys):\n",
    "    lista1 = []\n",
    "    lista2 = []\n",
    "    lista3 = []\n",
    "    lista4 = []\n",
    "    for i in range (0,range_):\n",
    "        fisier_citire = path +str(i)+ '.txt'\n",
    "        r = open(fisier_citire,'r')\n",
    "    \n",
    "        for linie in r:\n",
    "            articol_curent = json.loads(linie)\n",
    "            campuri = articol_curent[camp]\n",
    "\n",
    "            v_key = \"\"\n",
    "            for elem in campuri:\n",
    "                v_key += elem + ' '\n",
    "                \n",
    "            ## Prima lista ( 1 si 3)\n",
    "            if v_key == key:\n",
    "                fos_list = articol_curent['fos']\n",
    "                \n",
    "                max_ = 0\n",
    "                max_name = \"\"\n",
    "                \n",
    "                for elem in fos_list:\n",
    "                    lista1.append(elem['name'])  \n",
    "                    if elem['w'] > max_:\n",
    "                        max_ = elem['w']\n",
    "                        max_name = elem['name']\n",
    "                lista3.append(max_name)\n",
    "            \n",
    "            ## A doua lista (2 si 4) \n",
    "            if v_key in keys:\n",
    "\n",
    "                fos_list = articol_curent['fos']\n",
    "                \n",
    "                max_ = 0\n",
    "                max_name = \"\"\n",
    "                \n",
    "                for elem in fos_list:\n",
    "                    lista2.append(elem['name'])  \n",
    "                    if elem['w'] > max_:\n",
    "                        max_ = elem['w']\n",
    "                        max_name = elem['name']\n",
    "                lista4.append(max_name)\n",
    "\n",
    "        r.close()\n",
    "    return [lista1,lista2,lista3,lista4]\n",
    "\n",
    "def process(file, nr):\n",
    "    # Citeste dictionarul de {venue:venue_encoding}\n",
    "    r = open(file,'r')\n",
    "    w = open('results_avg_complete.txt','w')\n",
    "    X_dict = json.load(r)\n",
    "    r.close()\n",
    "    procent1 = 0\n",
    "    procent2 = 0\n",
    "    total_elems = 0\n",
    "    \n",
    "    for key in X_dict:\n",
    "        total_elems += 1\n",
    "        if total_elems % 100 == 0:\n",
    "            print(total_elems)\n",
    "            \n",
    "        # Creaza dictionar nou\n",
    "        new_X_dict = elimina_elem_dupa_cheie(X_dict, key)\n",
    "        # Calculeaza distantele\n",
    "        distante = calculeaza_distante(X_dict[key],new_X_dict, nr) \n",
    "        \n",
    "        # Ia in considerare toate fos\n",
    "        # Formeaza prima lista\n",
    "        keys = []\n",
    "        for elem in distante:\n",
    "            keys.append(elem[0])\n",
    "            \n",
    "        [l1,l2,l1_one,l2_one] = get_all('../DATE/preprocess_venue/venue_final/file', 196, 'venue', key, keys)\n",
    "        \n",
    "        # Calculeaza lista elementelor comune\n",
    "        l_c1 = list(set(l1).intersection(l2))\n",
    "        \n",
    "        # Calculeaza procentul de corectitudine\n",
    "        procent1 += ((len(l_c1) * 100 )/ len (l1))\n",
    "        \n",
    "        # Calculeaza lista elementelor comune\n",
    "        l_c2 = list(set(l1_one).intersection(l2_one))\n",
    "        \n",
    "        # Calculeaza procentul de corectitudine\n",
    "        procent2 += ((len(l_c2) * 100 )/ len (l1_one))   \n",
    "        #print(len(l1),len(l2),len(l1_one),len(l2_one),len(l_c1), len(l_c2), procent1,procent2)\n",
    "        w.write(str(len(l1)) + ' ' + str( len(l2)) + ' ' + str(len(l1_one)) + ' ' + str(len(l2_one)) + ' ' + str(len(l_c1))+ ' ' + str(len(l_c2))+ ' ' + str(procent1)+ ' ' + str(procent2))\n",
    "        w.write('\\n')\n",
    "        \n",
    "    procent1 /= total_elems\n",
    "    procent2 /= total_elems\n",
    "    \n",
    "    return [procent1,procent2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n"
     ]
    }
   ],
   "source": [
    "process('../DATE/preprocess_venue/w2v_sum_50_c.txt', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
