{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESARE VENUE\n",
    "- Extrage venues in litere mici\n",
    "- Elimina punctuatia \n",
    "- Elimina stopwords\n",
    "- Elimina cuvintele care nu sunt in engleza\n",
    "- Elimina articolele pentru care venues sunt goale\n",
    "- Calculez numarul de aparitii pentru fiecare cuvant\n",
    "- Elimin dupa numarul de aparitii\n",
    "    - [5, 1000]\n",
    "    - [25, 5000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # pentru fisier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library')\n",
    "\n",
    "from json_file_preprocessing import *\n",
    "from text_preprocessing import *\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,196):\n",
    "    fisier_citire = '../DATE/preprocess_abstract/3lemma/file'+str(i)+'.txt'\n",
    "    fisier_scriere = '../DATE/preprocess_venue/1/file'+str(i)+'.txt'\n",
    "    \n",
    "    r = open(fisier_citire,'r')\n",
    "    w = open(fisier_scriere,'w')\n",
    "    \n",
    "    for linie in r:\n",
    "        articol_curent = json.loads(linie)\n",
    "        venue = articol_curent['venue']\n",
    "        # lower + punctuatie\n",
    "        venue = elimina_punctuatia_propozitie(venue)\n",
    "        # stop_words\n",
    "        venue = elimina_stopwords_propozitie(venue)\n",
    "        # non-eng\n",
    "        venue = elimina_non_eng_propozitie(venue)\n",
    "        articol_curent['venue'] = venue\n",
    "        w.write(json.dumps(articol_curent))\n",
    "        w.write('\\n')\n",
    "        \n",
    "    r.close()\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,196):\n",
    "    fisier_citire = '../DATE/preprocess_venue/25_5000/file'+str(i)+'.txt'\n",
    "    fisier_scriere = '../DATE/preprocess_venue/25_5000_2/file'+str(i)+'.txt'\n",
    "    r = open(fisier_citire,'r')\n",
    "    w = open(fisier_scriere,'w')\n",
    "    for linie in r:\n",
    "        articol_curent = json.loads(linie)\n",
    "        venue = articol_curent['venue']\n",
    "        #venue = elimina_denumiri_geografice(venue)\n",
    "        if venue == []:\n",
    "            continue\n",
    "        articol_curent['venue'] = venue\n",
    "        w.write(json.dumps(articol_curent))\n",
    "        w.write('\\n')\n",
    "        \n",
    "    r.close()\n",
    "    w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculez dictionar de aparitii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_words = {}\n",
    "for i in range (0,196):\n",
    "    fisier_citire = '../DATE/preprocess_venue/venue_final/file'+str(i)+'.txt'\n",
    "    r = open(fisier_citire,'r')\n",
    "    for linie in r:\n",
    "        articol_curent = json.loads(linie)\n",
    "        venue = articol_curent['venue']\n",
    "        dict_words = dict_aparitii_propozitie(venue, dict_words)\n",
    "    r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "print(len(dict_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_dict = sort_dict_value(dict_words)\n",
    "w = open('../DATE/preprocess_venue/dict_words.txt','w')\n",
    "w.write(json.dumps(dict_words))\n",
    "w.close()\n",
    "w = open('../DATE/preprocess_venue/dict_words_sorted.txt','w')\n",
    "w.write(json.dumps(sort_dict))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "## Citeste dictionar aparitii\n",
    "fisier_citire ='../DATE/preprocess_venue/dict_words.txt'\n",
    "r = open(fisier_citire,'r')\n",
    "dict_words = json.load(r)\n",
    "r.close()\n",
    "print(len(dict_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimin cuvinte dupa aparitie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,196):\n",
    "    fisier_citire = '../DATE/preprocess_venue/venue_final/file'+str(i)+'.txt'\n",
    "    fisier_scriere = '../DATE/preprocess_venue/5_1000/file'+str(i)+'.txt'\n",
    "    r = open(fisier_citire,'r')\n",
    "    w = open(fisier_scriere,'w')\n",
    "    \n",
    "    for linie in r:\n",
    "        articol_curent = json.loads(linie)\n",
    "        articol_curent['venue'] = elimina_aparitii_propozitie(articol_curent['venue'],dict_words,5,1000)\n",
    "        w.write(json.dumps(articol_curent))\n",
    "        w.write('\\n')\n",
    "    r.close()\n",
    "    w.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0,196):\n",
    "    fisier_citire = '../DATE/preprocess_venue/venue_final/file'+str(i)+'.txt'\n",
    "    fisier_scriere = '../DATE/preprocess_venue/25_5000/file'+str(i)+'.txt'\n",
    "    r = open(fisier_citire,'r')\n",
    "    w = open(fisier_scriere,'w')\n",
    "    \n",
    "    for linie in r:\n",
    "        articol_curent = json.loads(linie)\n",
    "        articol_curent['venue'] = elimina_aparitii_propozitie(articol_curent['venue'],dict_words,25,5000)\n",
    "        w.write(json.dumps(articol_curent))\n",
    "        w.write('\\n')\n",
    "    r.close()\n",
    "    w.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculeaza IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1960000\n"
     ]
    }
   ],
   "source": [
    "n = calculeaza_nr_articole('../DATE/preprocess_venue/2/file', 196)\n",
    "print(n)\n",
    "idf = calculeaza_idf('../DATE/preprocess_venue/venue_final/file', 196, n, camp='venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "print(len(idf))\n",
    "w = open('../DATE/preprocess_venue/idf.txt','w')\n",
    "w.write(json.dumps(idf))\n",
    "w.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculeaza TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1453\n"
     ]
    }
   ],
   "source": [
    "r = open('../DATE/preprocess_venue/idf.txt','r') \n",
    "idf = json.load(r)\n",
    "print(len(idf))\n",
    "calculeaza_tf_idf('../DATE/preprocess_venue/venue_final/file','../DATE/preprocess_venue/tf_idf/file', 196, idf, 'venue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
