{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESARE VENUE\n",
    "### 1. Extrage venues in litere mici\n",
    "### 2. Elimina punctuatia \n",
    "### 3. Elimina cuvintele care nu sunt in engleza\n",
    "### 4. Elimina stopwords\n",
    "### 5. Calculez numarul de aparitii pentru fiecare cuvant\n",
    "### 6. Elimin cuvinte cu aparitie mai mare de 15 si de 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # pentru fisier\n",
    "import string # pentru lower si punctuation\n",
    "from nltk.corpus import wordnet # pentru verificare limbii\n",
    "from nltk.corpus import stopwords # pentru eliminare stopwords\n",
    "import itertools # pentru sortare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrage_venues(file):\n",
    "    venues = []\n",
    "    readFile = open(file,'r',encoding='utf-8')\n",
    "\n",
    "    for line in readFile:\n",
    "        current_paper = json.loads(line)\n",
    "        current_venue = current_paper['venue']\n",
    "        venues.append(current_venue.lower())\n",
    "    readFile.close()\n",
    "    return venues\n",
    "\n",
    "def elimina_punctuatia(venues):\n",
    "    new_venues = []\n",
    "    \n",
    "    for venue in venues:\n",
    "        \n",
    "        word = \"\"\n",
    "        new_current_venue = []\n",
    "        \n",
    "        for ch in venue:\n",
    "            if ch == ' ' or ch =='-':\n",
    "                new_current_venue.append(word)\n",
    "                word = \"\"\n",
    "            else:\n",
    "                if ch not in string.punctuation:\n",
    "                    word += ch\n",
    "        new_current_venue.append(word)\n",
    "        new_venues.append(new_current_venue)\n",
    "        \n",
    "    return new_venues\n",
    "\n",
    "def elimina_non_eng(venues):\n",
    "    new_venues = []\n",
    "    \n",
    "    for venue in venues:\n",
    "        new_current_venue = []\n",
    "        for elem in venue:\n",
    "            if wordnet.synsets(elem):\n",
    "                new_current_venue.append(elem)\n",
    "        new_venues.append(new_current_venue)\n",
    "    return new_venues\n",
    "\n",
    "def elimina_stopwords(venues):\n",
    "    new_venues = []\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    for venue in venues:\n",
    "        new_current_venue = []\n",
    "        for elem in venue:\n",
    "            if elem not in stop_words:\n",
    "                new_current_venue.append(elem)\n",
    "        new_venues.append(new_current_venue)\n",
    "    return new_venues\n",
    "\n",
    "def calculeaza_nr_aparitii(venues):\n",
    "    # Calculez numarul total de cuvinte\n",
    "    words_dict = {}\n",
    "    word_list = []\n",
    "    for venue in venues:\n",
    "        for elem in venue:\n",
    "            try:\n",
    "                words_dict[elem] += 1\n",
    "            except:\n",
    "                words_dict[elem] = 1\n",
    "                word_list.append(elem)\n",
    "                \n",
    "    return words_dict, word_list\n",
    "\n",
    "def elimina_cuv_dupa_aparitie(word_dict, word_list,frecv):\n",
    "    new_word_list = []\n",
    "    \n",
    "    for word in word_list:\n",
    "        if word_dict[word] < frecv:\n",
    "            new_word_list.append(word)\n",
    "    return new_word_list\n",
    "\n",
    "def elimina_venue(venues,word_list_reduced):\n",
    "    new_venues = []\n",
    "    for venue in venues:\n",
    "        new_current_venue = []\n",
    "        for elem in venue:\n",
    "            if elem in word_list_reduced:\n",
    "                new_current_venue.append(elem)\n",
    "        new_venues.append(new_current_venue)\n",
    "    return new_venues\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functii auxiliare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functii auxiliare\n",
    "def print_ll(listaDeListe, numeFisier):\n",
    "    numeFisier += \".json\"\n",
    "    wFile = open(numeFisier,'w')\n",
    "    wFile.write(json.dumps(listaDeListe))\n",
    "    wFile.close()\n",
    "\n",
    "def preety_print_ll(listaDeListe, numeFisier):\n",
    "    numeFisier += \"_pp.txt\"\n",
    "    wFile = open(numeFisier,'w')\n",
    "    for lista in listaDeListe:\n",
    "        for elem in lista:\n",
    "            wFile.write(elem)\n",
    "            wFile.write(' ')\n",
    "        wFile.write('\\n')\n",
    "    wFile.close()\n",
    "\n",
    "def preety_print_l(lista, numeFisier):\n",
    "    numeFisier += \"_ppl.txt\"\n",
    "    wFile = open(numeFisier,'w')\n",
    "    for elem in lista:\n",
    "        wFile.write(elem)\n",
    "        wFile.write('\\n')\n",
    "    wFile.close()\n",
    "    \n",
    "def print_dict(dict_, numeFisier):\n",
    "    numeFisier += \".json\"\n",
    "    wf = open(numeFisier,\"w\")\n",
    "    wf.write(json.dumps(dict_))\n",
    "    wf.close()\n",
    "    \n",
    "def eliminare_duplicate_si_vide(lista):\n",
    "    lista.sort()\n",
    "    sort_lista = list(lista for lista,_ in itertools.groupby(lista))\n",
    "    if sort_lista[0] == []:\n",
    "        return sort_lista[1:]\n",
    "    return sort_lista\n",
    "    \n",
    "    \n",
    "def maxim_aparitii(word_list, word_dict):\n",
    "    max_ap = 0\n",
    "    for elem in word_list:\n",
    "        if word_dict[elem] > max_ap:\n",
    "            max_ap = word_dict[elem]\n",
    "    return max_ap\n",
    "\n",
    "def sortare_dictionar(word_dict):\n",
    "    word_dict_sorted = {}\n",
    "    for w in sorted(word_dict, key=word_dict.get, reverse=True):\n",
    "        word_dict_sorted[w] = word_dict[w]\n",
    "    return word_dict_sorted\n",
    "\n",
    "def append_listeDeListe(new_list, old_list):\n",
    "    for elem in new_list:\n",
    "        old_list.append(elem)\n",
    "    return old_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4264\n"
     ]
    }
   ],
   "source": [
    "venues0 = extrage_venues('../../dblp-ref/dblp-final-0.json')\n",
    "venues1 = extrage_venues('../../dblp-ref/dblp-final-1.json')\n",
    "venues2 = extrage_venues('../../dblp-ref/dblp-final-2.json')\n",
    "venues3 = extrage_venues('../../dblp-ref/dblp-final-3.json')\n",
    "\n",
    "venues = append_listeDeListe(venues0,venues1)\n",
    "venues = eliminare_duplicate_si_vide(venues)\n",
    "\n",
    "\n",
    "venues = append_listeDeListe(venues2,venues)\n",
    "venues = eliminare_duplicate_si_vide(venues)\n",
    "\n",
    "venues = append_listeDeListe(venues3,venues)\n",
    "venues = eliminare_duplicate_si_vide(venues)\n",
    "\n",
    "print(len(venues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesare venues pasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810\n"
     ]
    }
   ],
   "source": [
    "venues = elimina_punctuatia(venues)\n",
    "venues = elimina_non_eng(venues)\n",
    "venues = elimina_stopwords(venues)\n",
    "venues = eliminare_duplicate_si_vide(venues)\n",
    "print(len(venues))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ll(venues,\"all_venues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict, word_list = calculeaza_nr_aparitii(venues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n",
      "1542\n"
     ]
    }
   ],
   "source": [
    "print(len(word_list))\n",
    "print(len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1542\n"
     ]
    }
   ],
   "source": [
    "word_dict_sorted = sortare_dictionar(word_dict)\n",
    "print(len(word_dict_sorted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1380\n",
      "1306\n"
     ]
    }
   ],
   "source": [
    "word_list_reduced15 = elimina_cuv_dupa_aparitie(word_dict, word_list,15)\n",
    "word_list_reduced10 = elimina_cuv_dupa_aparitie(word_dict, word_list,10)\n",
    "print(len(word_list_reduced15))\n",
    "print(len(word_list_reduced10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elimina cuvintele"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10145\n",
      "11015\n"
     ]
    }
   ],
   "source": [
    "venues_reduced_15 = elimina_venue(venues,word_list_reduced15)\n",
    "venues_reduced_10 = elimina_venue(venues,word_list_reduced10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3810\n",
      "3810\n"
     ]
    }
   ],
   "source": [
    "print(len(venues_reduced_15))\n",
    "print(len(venues_reduced_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1626\n",
      "1385\n"
     ]
    }
   ],
   "source": [
    "venues_final_15 = eliminare_duplicate_si_vide(venues_reduced_15)\n",
    "venues_final_10 = eliminare_duplicate_si_vide(venues_reduced_10)\n",
    "print(len(venues_final_15))\n",
    "print(len(venues_final_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_ll(venues_final_15, \"venues_reduced_15\")\n",
    "print_ll(venues_final_10, \"venues_reduced_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
