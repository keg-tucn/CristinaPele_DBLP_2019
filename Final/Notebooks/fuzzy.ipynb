{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../library')\n",
    "from clustering import *\n",
    "from helpers import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(X):\n",
    "    X_list = []\n",
    "    for elem in X:\n",
    "        X_list.append(X[elem])\n",
    "    return X_list\n",
    "\n",
    "def get_keys(X):\n",
    "    X_list = []\n",
    "    for elem in X:\n",
    "        X_list.append(elem)\n",
    "    return X_list\n",
    "\n",
    "###\n",
    "### Transforma un obiect fcm [[elems_clasa_0],..,[elem_clasa_n]] in lista de labels [class_elem_0, .., class_elem_n].\n",
    "### param labels: obiect de tip fcm.\n",
    "### return lista.\n",
    "###\n",
    "def create_class_labels(labels,venues, size):\n",
    "    l = np.zeros(size, dtype=int)\n",
    "    i = 0\n",
    "    for class_ in labels:\n",
    "        for elem in class_:\n",
    "            l[elem] = i\n",
    "        i += 1\n",
    "    dict_ = {}\n",
    "    for i,elem in enumerate(venues):\n",
    "        dict_[elem] = int(l[i])\n",
    "    return dict_\n",
    "\n",
    "def run_fuzzy(path, print_ = False):\n",
    "    r = open(path)\n",
    "    X = json.load(r)\n",
    "    r.close()\n",
    "    \n",
    "    X_values = get_values(X)\n",
    "    X_keys = get_keys(X)\n",
    "    \n",
    "    if print_ == True:\n",
    "        print('size vector ',len(X), len(X_values))\n",
    "    xmeans = apply_XMeans(X_values,1,100)\n",
    "    \n",
    "    cls = len(xmeans.get_clusters())\n",
    "    \n",
    "    fcm = apply_fuzzy(X_values,cls)\n",
    "    labels = fcm.get_membership()\n",
    "    \n",
    "    i = 0\n",
    "    X_dict = {}\n",
    "    for elem in labels:\n",
    "        X_dict[X_keys[i]] = elem \n",
    "        i+=1\n",
    "    return X_dict, cls\n",
    "    \n",
    "\n",
    "###\n",
    "### Transforma lista de weights a clusterelor in dictionar de forma {cluster:weight}, daca weight este mai \n",
    "### mare decat mijlocul de valori din weights initial.\n",
    "### param weights: lista de weights initiala.\n",
    "### return dict_ sau -1 daca nu este nici o valoare din lista  mai maire de valoarea de middle.\n",
    "###\n",
    "def get_class_weights(weights):\n",
    "    dict_ = {}\n",
    "    min_ = min(weights)\n",
    "    max_ = max(weights)\n",
    "    middle = (max_ + min_)/2\n",
    "    for i in range(0,len(weights)):\n",
    "        if weights[i] >= middle:\n",
    "            dict_[i] = weights[i]\n",
    "            \n",
    "    if len(dict_) == 0:\n",
    "        return -1\n",
    "    return dict_\n",
    "\n",
    "\n",
    "    \n",
    "def print_results(mem, path_in, path_out, nrFiles, space= False):\n",
    "    excluded = 0\n",
    "    for i in range(0, nrFiles):\n",
    "        r = open(path_in+str(i)+'.txt', 'r')\n",
    "        w = open(path_out+str(i)+'.txt', 'w')\n",
    "        \n",
    "        for line in r:\n",
    "            art_crt = json.loads(line)\n",
    "            new_art = {}\n",
    "            new_art['id'] = art_crt['id']\n",
    "            new_art['venue'] = art_crt['venue']\n",
    "            new_art['abstract'] = art_crt['abstract']\n",
    "            new_art['fos'] = art_crt['fos']\n",
    "            venue = \"\"\n",
    "            for elem in art_crt[\"venue\"]:\n",
    "                venue+= elem + \" \"\n",
    "            if space == False:\n",
    "                venue = venue[0:len(venue)-1]\n",
    "            try:\n",
    "                new_art['class_weights'] = get_class_weights(mem[venue])\n",
    "            except KeyError:\n",
    "                excluded += 1\n",
    "            \n",
    "            w.write(json.dumps(new_art))\n",
    "            w.write('\\n')\n",
    "            \n",
    "        w.close()\n",
    "        r.close()\n",
    "    return excluded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18704399466514587, -0.08676527440547943, -0.18396879732608795, 0.18725839257240295, 0.03192371129989624, 0.18220753967761993, 0.03831414505839348, 0.01378848496824503, -0.2730606198310852, 0.06354214996099472, -0.12895317375659943, -0.04770169034600258, -0.21216946840286255, -0.13878481090068817, 0.1785440742969513, 0.11427146941423416, -0.15266621112823486, -0.09526103734970093, -0.009971139021217823, -0.03551775589585304, 0.0804772898554802, -0.2227117121219635, -0.04306257143616676, -0.21697477996349335, -0.04758020117878914, -0.024065377190709114, -0.10948725044727325, -0.013623390346765518, -0.12689338624477386, -0.0034820500295609236, -0.10269936919212341, 0.2691926956176758, -0.15131424367427826, -0.15458175539970398, -0.060041822493076324, -0.13167624175548553, 0.05622607469558716, 0.13076990842819214, -0.07614551484584808, -0.20526808500289917, -0.006213625892996788, 0.07290535420179367, 0.016262346878647804, -0.22367945313453674, 0.07111503183841705, 0.028409281745553017, 0.193411722779274, -0.06798113137483597, 0.21863262355327606, -0.22639167308807373, 0.05926889553666115, 0.07588707655668259, -0.06460528075695038, -0.17582327127456665, 0.015071291476488113, -0.043209731578826904, 0.08263149112462997, -0.0455055795609951, -0.21092359721660614, -0.02517332136631012, 0.12586955726146698, -0.07046263664960861, -0.1296544075012207, 0.004168973304331303, 0.185337632894516, -0.22201071679592133, -0.11337075382471085, 0.020260974764823914, -0.04107116907835007, -0.20861691236495972, 0.13598106801509857, 0.03115888312458992, 0.04215829446911812, 0.3272152841091156, -0.029093120247125626, 0.07892632484436035, 0.034032098948955536, 0.20526224374771118, 0.013534775003790855, -0.14806661009788513, 0.006586336065083742, 0.00336667662486434, -0.08296506851911545, 0.1986788809299469, -0.25196751952171326, -0.09764953702688217, -0.14706529676914215, -0.20933815836906433, -0.037135399878025055, 0.11628787964582443, -0.04893898591399193, -0.17027658224105835, 0.06827696412801743, -0.24504055082798004, -0.2319621592760086, 0.06281841546297073, 0.009230178780853748, -0.09648819267749786, -0.0020268047228455544, -0.18697760999202728, 0.1593445986509323, -0.06614785641431808, -0.15531465411186218, -0.19274695217609406, 0.1585112363100052, -0.09934898465871811, 0.0856538638472557, 0.1116260439157486, 0.09702949225902557, -0.027506571263074875, -0.20587167143821716, 0.0595502033829689, -0.05463122949004173, 0.0461384542286396, -0.36603614687919617, -0.0968746766448021, -0.027808425948023796, 0.10223807394504547, 0.09096740931272507, -0.001408956479281187, 0.026371365413069725, -0.15677784383296967, -0.20812679827213287, 0.23361530900001526, -0.273964524269104, -0.0397203303873539, 0.2480112761259079, -0.23224841058254242, 0.15614743530750275, -0.07426908612251282, 0.16159141063690186, 0.03186628967523575, 0.1107274740934372, -0.13728386163711548, 0.023714346811175346, 0.03136172890663147, -0.1718156337738037, -0.11712827533483505, 0.07661078125238419, 0.02718096412718296, 0.10131051391363144, 0.11734525114297867, 0.16139212250709534, -0.07147259265184402, -0.006124564912170172, 0.22630807757377625, -0.0004526482371147722, -0.04757217317819595, 0.28964418172836304, 0.1394573450088501, -0.20743361115455627, -0.05983051285147667, 0.0021555630955845118, -0.18949253857135773, -0.016716228798031807, -0.10414087772369385, 0.004838207736611366, -0.3016480803489685, -0.09392917901277542, 0.04729626700282097, 0.041117552667856216, -0.06020130217075348, -0.026617275550961494, 0.1741480529308319, 0.08555395156145096, 0.036199137568473816, -0.0337032750248909, -0.19850800931453705, 0.0042892643250525, -0.12263989448547363, 0.05680457130074501, -0.24189183115959167, 0.254104346036911, -0.1844952404499054, 0.3305869698524475, 0.03651072829961777, -0.14762091636657715, 0.15340256690979004, -0.004149956628680229, 0.13917021453380585, -0.02827666886150837, 0.2497113049030304, -0.08120100200176239, -0.2531885802745819, 0.0009845142485573888, -0.06175055354833603, 0.000576486811041832, 0.22572526335716248, 0.037869617342948914, 0.21543161571025848, 0.039381373673677444, -0.22931165993213654, -0.07307013869285583, 0.10220992565155029, -0.15058180689811707, -0.3424331843852997, 0.1875460296869278, -0.20168113708496094, -0.1289650797843933, -0.08299653232097626, 0.216246098279953, -0.14751718938350677, 0.22500421106815338, -0.21348373591899872, -0.011379723437130451, 0.10538576543331146, 0.021625380963087082, 0.0944221019744873, -0.051485635340213776, -0.07557032257318497, 0.1403885930776596, 0.10120490938425064, -0.10692194849252701, 0.10579260438680649, 0.0123042743653059, 0.00868173036724329, -0.05106949433684349, -0.20967711508274078, -0.03334322199225426, -0.1568707823753357, 0.11976639181375504, 0.01226124633103609, 0.05569411441683769, -0.0700131505727768, -0.09974464774131775, -0.051390863955020905, -0.10684667527675629, 0.11266434192657471, -0.11946223676204681, -0.09030178934335709, -0.021246664226055145, -0.08580207824707031, 0.34435907006263733, -0.03794688731431961, 0.25407737493515015, -0.18790534138679504, -0.09576554596424103, 0.03886927291750908, -0.026303360238671303, 0.09534512460231781, -0.08658064901828766, -0.13921383023262024, -0.01936298795044422, 0.05002591386437416, 0.056848689913749695, -0.3230506181716919, -0.0873594880104065, -0.07167868316173553, 0.09883398562669754, 0.1684533804655075, -0.029891017824411392, 0.007721578236669302, 0.2824363112449646, 0.07732624560594559, -0.22156374156475067, 0.2822006940841675, 0.058253586292266846, -0.05204420164227486, 0.024221030995249748, 0.1341775506734848, -0.031558334827423096, 0.02014338970184326, -0.022130772471427917, -0.21962565183639526, -0.1756199151277542, 0.0171978697180748, 0.1233416423201561, -0.08915339410305023, 0.09998409450054169, 0.02339223213493824, 0.0967864990234375, 0.18175294995307922, -0.09600873291492462, 0.07910414040088654, 0.022850770503282547, -0.3109574615955353, 0.09055832773447037, -0.04055209085345268, 0.2482929229736328, -0.07990528643131256, -0.05490780249238014, 0.1755945235490799, -0.022391648963093758, -0.03998848795890808, 0.22916464507579803, -0.027741942554712296, -0.05020884796977043, -0.3088078200817108, 0.045420560985803604, -0.11163327097892761, -0.16455258429050446, 0.11078295111656189, -0.26502275466918945, -0.08081672340631485, -0.09518199414014816, -0.0948716551065445, -0.12299343943595886, 0.16795451939105988, 0.05650395154953003, -0.1348891258239746]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-6696e751a7be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcls_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mmem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_fuzzy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Date/doc2vec/Venue/d2v_venue_complete.txt'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mcls_max\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mcls_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,100):\n",
    "    mem, cls = run_fuzzy('../Date/doc2vec/Venue/d2v_venue_complete.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583 10\n"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,100):\n",
    "    mem, cls = run_fuzzy('../Date/doc2vec/Venue/d2v_venue_complete.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "visual science technology [0.10002370240921045, 0.099977749561627, 0.09999121471022086, 0.10000474778067919, 0.10000989709720065, 0.09996811102121816, 0.09998910066543272, 0.09998889971427007, 0.10002618223876865, 0.10002039480137227]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Doc2vec/10clus_file', 169)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,100):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-pretrained/Venue/w2v_avg_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal imaging  [0.062457563862682385, 0.06251976879824536, 0.06249830320341451, 0.06250858759686233, 0.062488821345915616, 0.06250801785052491, 0.06249974353768769, 0.06251619698956132, 0.06248899577661364, 0.06249495802532904, 0.06252047807749468, 0.06251244587504413, 0.062493818532696914, 0.062497989021782455, 0.06250288032272092, 0.062491431183424095]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_pretrained/avg/16clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582 18\n"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,300):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-pretrained/Venue/w2v_sum_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal imaging  [0.08615150047415396, 0.042385720621338024, 0.036819198172155836, 0.03162353450943053, 0.03261382398213248, 0.08592740787413876, 0.03243745622509882, 0.04297335350791731, 0.08531209673743523, 0.08273420662993389, 0.08015613006260018, 0.032174717340213405, 0.04224920672864114, 0.031873102248243156, 0.04925139032777564, 0.03409255142479048, 0.0868746409147135, 0.08434996221928764]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_pretrained/sum/18clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583 24\n"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,300):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-gensim/Venue/w2v_gensim_avg_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal imaging  [0.04165587585150972, 0.041671916807365886, 0.041662413081522714, 0.041665060446269934, 0.04166885994216144, 0.04167237631238547, 0.04166948934237367, 0.041663151108971765, 0.04166638424599939, 0.04166813973397048, 0.041663426015580596, 0.0416708920196258, 0.04166803130191608, 0.041662617338378845, 0.04167346486604964, 0.041667061556429796, 0.041663236967043424, 0.04166776701072893, 0.04166998301418075, 0.04166943309799835, 0.041665439490585356, 0.0416648355061113, 0.04166814473404646, 0.041662000208794216]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_gensim/avg/24clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,300):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-gensim/Venue/w2v_gensim_sum_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_gensim/sum/20clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583 1\n"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,300):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-tensorflow/Venue/w2v_tf_avg_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal imaging  [0.20031791692564785, 0.19987774928417537, 0.1999013226920146, 0.19987146271349787, 0.20003154838466428]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_tensorflow/avg/2clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583 5\n"
     ]
    }
   ],
   "source": [
    "mem_max = []\n",
    "cls_max = 0\n",
    "for _ in range(0,300):\n",
    "    mem,cls = run_fuzzy('../Date/word2vec-tensorflow/Venue/w2v_tf_sum_50_c.txt')\n",
    "    if cls > cls_max:\n",
    "        cls_max = cls\n",
    "        mem_max = mem\n",
    "print(len(mem_max), cls_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal imaging  [0.20031791692564785, 0.19987774928417537, 0.1999013226920146, 0.19987146271349787, 0.20003154838466428]\n"
     ]
    }
   ],
   "source": [
    "for elem in mem_max:\n",
    "    print (elem, mem_max[elem])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "excluded = print_results(mem_max, '../Date/Initiale/Complet/file', '../Rezultate/Fuzzy/Venue/Word2vec_tensorflow/sum/5clus_file', 169, True)\n",
    "print(excluded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate fuzzy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Concateneaza o lista de string.\n",
    "### param list_: lista.\n",
    "### return camp: lista concatenata.\n",
    "###\n",
    "def extrage_camp(list_):\n",
    "    camp = \"\"\n",
    "    for elem in list_:\n",
    "        camp += elem + ' '\n",
    "    return camp[0:len(camp)-1]\n",
    "\n",
    "###\n",
    "### Verifica daca o cheie se gaseste intr-un dictionar si returneaza valoarea din dictionar.\n",
    "### param dict_cluster: dictionarul.\n",
    "### param nr_cluster: cheia\n",
    "### return True, valoare daca gaseste sau False, -1 daca nu gaseste\n",
    "###\n",
    "def is_in_cluster(dict_clusters, nr_cluster):\n",
    "    try :\n",
    "        return True, dict_clusters[nr_cluster]\n",
    "    except KeyError:\n",
    "        return False, -1\n",
    "\n",
    "\n",
    "###\n",
    "### Parcurge fisierele cu weight_cluster si creeaza un dictionar de forma {venue:weight} pentru un cluster dat.\n",
    "### param cluster: numarul clusterului pentru care se face cautarea (! In format string)\n",
    "### param path: calea spre fisiere\n",
    "### param nrFiles: numarul de fisiere\n",
    "### return cluster_dict: dictionarul cuu venues si weight asociat pentru clusterul cerut\n",
    "###\n",
    "def extragere_puncte_cluster(cluster, path, nrFiles):\n",
    "    cluster_dict = {}\n",
    "    for i in range(0, nrFiles):\n",
    "        file = path+str(i)+'.txt'\n",
    "        r = open(file,'r')\n",
    "        for line in r:\n",
    "            \n",
    "            art_crt = json.loads(line)\n",
    "            try:\n",
    "                includes, weight = is_in_cluster(art_crt['class_weights'],cluster) \n",
    "            except KeyError:\n",
    "                continue\n",
    "            if (includes == True):\n",
    "                venue = art_crt['venue']\n",
    "                venue = extrage_camp(venue)\n",
    "                try :\n",
    "                    cluster_dict[venue] += weight \n",
    "                except KeyError:\n",
    "                    cluster_dict[venue] = weight   \n",
    "        r.close()\n",
    "    return cluster_dict\n",
    "\n",
    "def calculeaza_sume_distante(elem, cluster_dict, model):\n",
    "    dist = 0\n",
    "    for elem_crt in cluster_dict:\n",
    "        if elem == elem_crt:\n",
    "            continue\n",
    "        dist += calculeaza_distanta(model[elem], model[elem_crt])\n",
    "    return dist\n",
    "\n",
    "def calcul_inter_cluster(model, cluster_dict): \n",
    "    # am un dict {venue: weight}\n",
    "    # am modelul care face corespondenta venue -> embedding\n",
    "    sum_total = 0\n",
    "    print(len(cluster_dict))\n",
    "    for elem_crt in cluster_dict:\n",
    "        for elem in cluster_dict:\n",
    "            if elem_crt == elem:\n",
    "                continue\n",
    "            sum_ = calculeaza_distanta(model[elem], model[elem_crt])\n",
    "            sum_ *= cluster_dict[elem]\n",
    "        sum_total += sum_\n",
    "        \n",
    "    return sum_total / len(cluster_dict)\n",
    "\n",
    "## cluster_dict : {venue:weight}\n",
    "def calc_centro(model, cluster_dict, dim): \n",
    "    sum_total = 0\n",
    "    \n",
    "    centroid = []\n",
    "    for i in range(0, dim):\n",
    "        centroid.append(0)\n",
    "    \n",
    "    for elem in cluster_dict:\n",
    "        elem_m = model[elem]\n",
    "        for i in range(0, dim):\n",
    "            centroid[i] += elem_m[i]\n",
    "            \n",
    "    for i in range(0, dim):\n",
    "        centroid[i] /= dim\n",
    "    return centroid\n",
    "\n",
    "###\n",
    "### Calcularea centroizilor din toate clusterele.\n",
    "### param model: model\n",
    "### param cls: id de cluster string\n",
    "### param nrClusters: numarul de clustere\n",
    "### param path: calea spre fisiere\n",
    "### param nrFiles: numarul de fisiere\n",
    "### return centroid_list: lista de controizi\n",
    "###\n",
    "def calcul_centroizi(model, cls, model_size, nrClusters, path, nrFiles):\n",
    "    centroid_list = []\n",
    "    for i in range(0,nrClusters):\n",
    "        cluster_dict = extragere_puncte_cluster(cls[i],path, nrFiles)\n",
    "        centroid_list.append(calc_centro(model, cluster_dict, model_size))\n",
    "    return centroid_list\n",
    "\n",
    "\n",
    "def calcul_intra_cluster(centroid_list):\n",
    "    dist_total = 0\n",
    "    \n",
    "    for centroid_crt in centroid_list:\n",
    "        dist = 0\n",
    "        for centroid in centroid_list:\n",
    "            if centroid == centroid_list:\n",
    "                continue\n",
    "            dist += calculeaza_distanta(centroid_crt, centroid)\n",
    "        dist_total += (dist/(len(centroid_list)-1))\n",
    "    print('HALO CENTRO', dist)\n",
    "    return dist / len(centroid_list)\n",
    "\n",
    "def process(nrClustere, cls, path, nrFiles, size_model):\n",
    "    total = 0\n",
    "    centroid_list = []\n",
    "    for i in range(0,nrClustere):\n",
    "        cluster_dict = extragere_puncte_cluster(cls[i],path, nrFiles)\n",
    "        #total += calcul_inter_cluster(X_dict, cluster_dict)\n",
    "        centroid_list.append(calc_centro(X_dict, cluster_dict, size_model))\n",
    "        \n",
    "    intra = calcul_intra_cluster(centroid_list)\n",
    "    total /= nrClustere    \n",
    "    return total, intra    \n",
    "\n",
    "## citeste modelul si elimina spatiul final din chei\n",
    "def read_model(path):\n",
    "    r = open(path, 'r')\n",
    "    X_dict = json.load(r)\n",
    "    r.close()\n",
    "    new_x_dict = {}\n",
    "    for elem in X_dict:\n",
    "        new_elem = elem[0:len(elem)-1]\n",
    "        new_x_dict[new_elem] = X_dict[elem]\n",
    "    return new_x_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 28.187422689179243\n",
      "0.0 2.8187422689179242\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/doc2vec/Venue/d2v_venue_complete.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "cls = ['0','1','2','3','4','5','6','7','8','9']\n",
    "\n",
    "total, intra = process(10,cls,'../Rezultate/Fuzzy/Venue/Doc2vec/10clus_file', 169, 300)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec pretrained avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 757.851469709355\n",
      "0.0 44.57949821819735\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-pretrained/Venue/w2v_avg_50_c.txt')\n",
    "cls = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16']\n",
    "\n",
    "total, intra = process(17,cls,'../Rezultate/Fuzzy/Venue/Word2vec_pretrained/avg/17clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec pretrained sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 2994.5703859272344\n",
      "0.0 176.15119917219025\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-pretrained/Venue/w2v_sum_50_c.txt')\n",
    "cls = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16']\n",
    "\n",
    "total, intra = process(17,cls,'../Rezultate/Fuzzy/Venue/Word2vec_pretrained/avg/17clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec gensim avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CENTRO 2065.3799057766714\n",
      "0.0 86.05749607402798\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-gensim/Venue/w2v_gensim_avg_50_c.txt')\n",
    "cls = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23']\n",
    "\n",
    "total, intra = process(24,cls,'../Rezultate/Fuzzy/Venue/Word2vec_gensim/avg/24clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec gensim sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 4014.226646235872\n",
      "0.0 200.7113323117936\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-gensim/Venue/w2v_gensim_sum_50_c.txt')\n",
    "cls = ['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19']\n",
    "\n",
    "total, intra = process(20,cls,'../Rezultate/Fuzzy/Venue/Word2vec_gensim/sum/20clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec tensorflow avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 68.91987249866045\n",
      "0.0 34.45993624933023\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-tensorflow/Venue/w2v_tf_avg_50_c.txt')\n",
    "cls = ['0','1']\n",
    "\n",
    "total, intra = process(2,cls,'../Rezultate/Fuzzy/Venue/Word2vec_tensorflow/avg/2clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec tensorflow sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HALO CENTRO 294.3558356232902\n",
      "0.0 58.871167124658044\n"
     ]
    }
   ],
   "source": [
    "X_dict = read_model('../Date/word2vec-tensorflow/Venue/w2v_tf_sum_50_c.txt')\n",
    "cls = ['0','1','2','3','4']\n",
    "\n",
    "total, intra = process(5,cls,'../Rezultate/Fuzzy/Venue/Word2vec_tensorflow/sum/5clus_file', 169, 50)\n",
    "print(total, intra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
