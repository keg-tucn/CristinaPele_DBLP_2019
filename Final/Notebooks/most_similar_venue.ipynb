{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../library')\n",
    "\n",
    "from helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### Concatenteaza o lista de string.\n",
    "### param list_: lista de string.\n",
    "### return string-ul rezultat dupa concatenare.\n",
    "###\n",
    "def get_key_from_lists(list_):\n",
    "    key = \"\"\n",
    "    for elem in list_:\n",
    "        key += elem + ' '\n",
    "    return key[0:len(key)-1]\n",
    "\n",
    "###\n",
    "### Calculeaza distanta euclidiana dintre un vector si o lista de vectori si returneaza o lista cu cei mai aporpiati nr.\n",
    "### param X: dictionar {cheie:vector}. -> vectorul\n",
    "### param X_dict: dictionar {chei:vectori} -> vectorii.\n",
    "### param nr: numarul de vecini cei mai apropiati pe care ii va returna.\n",
    "### return distante: dictionar {chei:vectori}.\n",
    "### \n",
    "def calculeaza_distante_p(X, X_dict, nr):\n",
    "    distante = {}\n",
    "    for elem in X_dict:\n",
    "        distante[elem] = distance.euclidean(X, X_dict[elem])        \n",
    "    distante = sort_dict_value(distante)\n",
    "    return distante[0:nr]\n",
    "\n",
    "###\n",
    "### Parcurge toate fisierele si creeaza un dictionar {venue:[list_of_fos]}.\n",
    "### file_path: calea spre fisiere.\n",
    "### param print_: printeaza log la 10 iteratii.\n",
    "### return dict_: dictionarul.\n",
    "###\n",
    "def get_dict_foses(file_path, print_ = False):\n",
    "    dict_ = {}\n",
    "    j = 0\n",
    "    for i in range(0,169):\n",
    "        if (print_):\n",
    "            if j % 10 == 0:\n",
    "                print(j)\n",
    "            j += 1\n",
    "        file = file_path + str(i) + '.txt'\n",
    "        r = open(file,'r')\n",
    "        \n",
    "        for linie in r:\n",
    "            articol_crt = json.loads(linie)\n",
    "            venue = articol_crt['venue']\n",
    "            venue = get_key_from_lists(venue)\n",
    "            fos = articol_crt['fos']\n",
    "            try:\n",
    "                fos_list = dict_[venue]\n",
    "            except KeyError:\n",
    "                fos_list = []\n",
    "            \n",
    "            for elem in fos:\n",
    "                fos_list.append(elem['name'])\n",
    "            \n",
    "            dict_[venue] = remove_duplicates(fos_list)\n",
    "\n",
    "        r.close()\n",
    "    return dict_\n",
    "\n",
    "###\n",
    "### Parcurge toate elementele unui dictionar de tipul {venues:[encoding]}\n",
    "### param dict_1: dictionarul.\n",
    "### param vecini: numarul de vecini cautati.\n",
    "### return dict_2: dictionar ce contine vecini nr de vecini [venue:[list_of_venues]] \n",
    "### \n",
    "def get_dict_similar_p(dict_1, vecini, del_=True):\n",
    "    dict_2 = {}\n",
    "    k = 0    \n",
    "    for key in dict_1:\n",
    "        \n",
    "        new_X_dict = elimina_elem_dupa_cheie(dict_1, key)\n",
    "        distante = calculeaza_distante_p(dict_1[key],new_X_dict, vecini) \n",
    "        list_ = []\n",
    "        \n",
    "        key = key[0:len(key)-1]\n",
    "        \n",
    "        for elem in distante:\n",
    "            if del_ == True:\n",
    "                list_.append(elem[0][0:len(elem[0])-1])\n",
    "            else:\n",
    "                list_.append(elem[0])\n",
    "        dict_2[key] = list_\n",
    "    print(len(dict_2))\n",
    "    return dict_2\n",
    "\n",
    "\n",
    "def get_dict_similar_abstr(dict_1, vecini, del_=True):\n",
    "    dict_2 = {}\n",
    "    k = 0    \n",
    "    for key in dict_1:\n",
    "        \n",
    "        new_X_dict = elimina_elem_dupa_cheie(dict_1, key)\n",
    "        distante = calculeaza_distante_p(dict_1[key],new_X_dict, vecini) \n",
    "        list_ = []\n",
    "        \n",
    "        for elem in distante:\n",
    "            if del_ == True:\n",
    "                list_.append(elem[0])\n",
    "            else:\n",
    "                list_.append(elem[0])\n",
    "        dict_2[key] = list_\n",
    "    print(len(dict_2))\n",
    "    return dict_2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_union(d1, d2):\n",
    "    union = []\n",
    "    union += d1\n",
    "    union += d2\n",
    "    union = remove_duplicates(union)\n",
    "    return len(union)\n",
    "\n",
    "def jacard(dict_venue_fos, dict_venue_vecini, p = False):\n",
    "    j = 0\n",
    "    i =0\n",
    "    \n",
    "    for venue_crt in dict_venue_vecini:\n",
    "        list_fos_vecini = []\n",
    "        for venue in dict_venue_vecini[venue_crt]:\n",
    "            list_fos_vecini+=dict_venue_fos[venue]    \n",
    "            \n",
    "        intersection = elemente_comune_lista(dict_venue_fos[venue_crt], list_fos_vecini)\n",
    "        union = compute_union(dict_venue_fos[venue_crt], list_fos_vecini)\n",
    "        j += (intersection/union)\n",
    "        \n",
    "        if p == True:\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "        i += 1\n",
    "    return j\n",
    "\n",
    "\n",
    "def process(dict_venue_fos, dict_venue_venues):   \n",
    "    procent_total = 0\n",
    "    k = 0\n",
    "    valids = 0\n",
    "    for elem in dict_venue_fos:\n",
    "        \n",
    "        l2 = []\n",
    "        l1 = dict_venue_fos[elem] # toate fos pt venue curent\n",
    "        \n",
    "        try:\n",
    "            for fos in dict_venue_venues[elem]: # caut fos de la vecini\n",
    "                l2 += dict_venue_fos[fos]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        l2 = remove_duplicates(l2)\n",
    "        valids += 1\n",
    "        \n",
    "        # Gasesc fos din venue curent care se gasesc si la vecini\n",
    "        l_comun = elemente_comune_lista(l1,l2)\n",
    "        \n",
    "        # jacard pentru A = fos care se gasesc si la vecini, B = fos pentru venue curent\n",
    "        proc = len(l_comun)/len(l1)\n",
    "        procent_total += proc        \n",
    "\n",
    "    procent_total /= valids\n",
    "    return procent_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_venue_fos = get_dict_foses('../Date/Initiale/Complet/file', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec gensim avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "0.48373119857968316\n",
      "3583\n",
      "0.60693685608885\n",
      "3583\n",
      "0.6737468739826491\n",
      "3583\n",
      "0.7189918664205573\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-gensim/Venue/w2v_gensim_avg_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec gensim sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "0.5199247488010289\n",
      "3583\n",
      "0.6513314723511857\n",
      "3583\n",
      "0.7161088588622757\n",
      "3583\n",
      "0.757171085436828\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-gensim/Venue/w2v_gensim_sum_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec tensorflow avg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "0.5853413101079363\n",
      "3583\n",
      "0.7066274244459667\n",
      "3583\n",
      "0.7644816978815915\n",
      "3583\n",
      "0.8005226829076263\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-tensorflow/Venue/w2v_tf_avg_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec tensorflow sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "0.6033530480964197\n",
      "3583\n",
      "0.7261841622156537\n",
      "3583\n",
      "0.7850338977920095\n",
      "3583\n",
      "0.8202889869238266\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-tensorflow/Venue/w2v_tf_sum_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec pretrained avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n",
      "0.5651990566801232\n",
      "3582\n",
      "0.6924654579370793\n",
      "3582\n",
      "0.7564209239091935\n",
      "3582\n",
      "0.7964951932591221\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-pretrained/Venue/w2v_avg_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec pretrained sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3582\n",
      "0.5758077083980073\n",
      "3582\n",
      "0.7072896469398123\n",
      "3582\n",
      "0.7725850128207393\n",
      "3582\n",
      "0.8122450315321679\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/word2vec-pretrained/Venue/w2v_sum_50_c.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# # dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_p(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3583\n",
      "0.622302801958108\n",
      "3583\n",
      "0.7485565617753093\n",
      "3583\n",
      "0.8078531925253469\n",
      "3583\n",
      "0.8425366455864072\n"
     ]
    }
   ],
   "source": [
    "r = open('../Date/doc2vec/Venue/d2v_venue_complete.txt', 'r')\n",
    "X_dict = json.load(r)\n",
    "r.close()\n",
    "\n",
    "# dict cu {venue:[similar_venues]}\n",
    "rang = [5,10,15,20]\n",
    "for elem in rang:\n",
    "    venues = get_dict_similar_abstr(X_dict,elem)\n",
    "\n",
    "    j = process(dict_venue_fos, venues)\n",
    "    print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "venue_neig = {'a':['ana','mere'], 'b':['mere','si','pere']}\n",
    "venue_fos = {'a':['1','2'],'ana':['2','3'], 'are':['4','1'], 'mere':['5', '6'], 'b':['2','5','1'], 'si':['6'],'pere':['6','2','3']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a : [1 2] v [2 3 5 6] i: [1 2] u: [2] r: 1/2\n",
    "b : [1 2 5 ] v [2 3 5 6] i: [1 2 5] u: [2 5] r: 2/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_p_2(dict_venue_fos, dict_venue_venues):   \n",
    "    procent_total = 0\n",
    "    k = 0\n",
    "    valids = 0\n",
    "    for elem in dict_venue_fos:\n",
    "        \n",
    "        l2 = []\n",
    "        l1 = dict_venue_fos[elem] # toate fos pt venue curent\n",
    "        \n",
    "        try:\n",
    "            for fos in dict_venue_venues[elem]: # caut fos de la vecini\n",
    "                l2 += dict_venue_fos[fos]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        l2 = remove_duplicates(l2)\n",
    "        valids += 1\n",
    "        \n",
    "        # Gasesc fos din venue curent care se gasesc si la vecini\n",
    "        l_comun = elemente_comune_lista(l1,l2)\n",
    "        \n",
    "        # jacard pentru A = fos care se gasesc si la vecini, B = fos pentru venue curent\n",
    "        proc = len(l_comun)/len(l1)\n",
    "        print(l_comun, l1)\n",
    "        print(proc)\n",
    "        procent_total += proc        \n",
    "    print(procent_total, valids)\n",
    "    procent_total /= valids\n",
    "    return procent_total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2'] ['1', '2']\n",
      "0.5\n",
      "['5', '2'] ['2', '5', '1']\n",
      "0.6666666666666666\n",
      "1.1666666666666665 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5833333333333333"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_p_2(venue_fos, venue_neig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
